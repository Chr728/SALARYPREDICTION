{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1014efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re \n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87444577",
   "metadata": {},
   "source": [
    "## Credentials for Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4694f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = 'AKIAZQ3DOOYC7J5PI25Z'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "bucket_name = 'comp333bucket'\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208713f0",
   "metadata": {},
   "source": [
    "## The list contains all the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b702dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CS_keywords = set(['python', 'pytorch', 'sql', 'mxnet', 'mlflow', 'einstein', 'theano', 'pyspark', 'solr', 'mahout',\n",
    " 'cassandra', 'aws', 'powerpoint', 'spark', 'pig', 'sas', 'java', 'nosql', 'docker', 'salesforce', 'scala', 'c++', 'net', 'tableau', 'pandas', 'scikitlearn', 'sklearn', 'matlab', 'scala', 'keras', 'tensorflow', 'clojure',\n",
    " 'caffe', 'scipy', 'numpy', 'matplotlib', 'vba', 'spss', 'linux', 'azure', 'cloud', 'gcp', 'mongodb', 'mysql', 'oracle',\n",
    " 'redshift', 'snowflake', 'kafka', 'javascript', 'qlik', 'jupyter', 'perl', 'bigquery', 'unix', 'react',\n",
    " 'scikit', 'powerbi', 's3', 'ec2', 'lambda', 'ssrs', 'kubernetes', 'hana', 'spacy', 'tf', 'django', 'sagemaker',\n",
    " 'seaborn', 'mllib', 'github', 'git', 'elasticsearch', 'splunk', 'airflow', 'looker', 'rapidminer', 'birt', 'pentaho',\n",
    "'jquery', 'nodejs', 'd3', 'plotly', 'bokeh', 'xgboost', 'rstudio', 'shiny', 'dash', 'h20', 'h2o', 'hadoop', 'mapreduce',\n",
    " 'hive', 'cognos', 'angular', 'nltk', 'flask', 'node', 'firebase', 'bigtable', 'rust', 'php', 'cntk', 'lightgbm',\n",
    " 'kubeflow', 'rpython', 'unixlinux', 'postgressql', 'postgresql', 'postgres', 'hbase', 'dask', 'ruby', 'julia', 'tensor',\n",
    " 'dplyr','ggplot2','esquisse','bioconductor','shiny','lubridate','knitr','mlr','quanteda','dt','rcrawler','caret','rmarkdown',\n",
    " 'leaflet','janitor','ggvis','plotly','rcharts','rbokeh','broom','stringr','magrittr','slidify','rvest',\n",
    " 'rmysql','rsqlite','prophet','glmnet','text2vec','snowballc','quantmod','rstan','swirl','datasciencer', \n",
    " 'amazon web services', 'google cloud', 'sql server',\n",
    "  'cleansing', 'chatbot', 'cleaning', 'blockchain', 'causality', 'correlation', 'bandit', 'anomaly', 'kpi',\n",
    " 'dashboard', 'geospatial', 'ocr',  'pca', 'gis', 'svm', 'svd', 'tuning', 'hyperparameter', 'hypothesis',\n",
    " 'salesforcecom', 'segmentation', 'biostatistics', 'unsupervised', 'supervised', 'exploratory',\n",
    " 'recommender', 'recommendations', 'research', 'sequencing', 'probability', 'reinforcement', 'graph', 'bioinformatics',\n",
    "  'knn', 'etl', 'normalization', 'classification', 'optimizing', 'prediction', 'forecasting',\n",
    " 'clustering', 'optimization', 'visualization', 'nlp', 'c#',\n",
    " 'regression', 'logistic', 'cnn', 'glm',\n",
    " 'rnn', 'lstm', 'gbm', 'boosting', 'recurrent', 'convolutional', 'bayesian',\n",
    " 'bayes', 'random forest', 'natural language processing', 'machine learning', 'decision tree', 'deep learning', 'experimental design',\n",
    " 'time series', 'nearest neighbors', 'neural network', 'support vector machine', 'computer vision', 'machine vision', 'dimensionality reduction',\n",
    " 'text analytics',  'a/b testing', 'data mining', 'kajsadouas', 'senior','intern'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e0bb4",
   "metadata": {},
   "source": [
    "## Get the list of keywords that actualling appear in the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a5067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key = 'merged_dataset.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "content = obj['Body'].read()\n",
    "merged_df = pd.read_csv(BytesIO(content), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c446662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bokeh', 'boosting', 'normalization', 'intern', 'docker', 'pyspark', 'spark', 'visualization', 'natural language processing', 'python', 'nltk', 'redshift', 'plotly', 'sas', 'a/b testing', 'tuning', 'numpy', 'ggplot2', 'senior', 'h2o', 'rust', 'bandit', 'nearest neighbors', 'rvest', 'seaborn', 'github', 'hypothesis', 'node', 'dash', 'hyperparameter', 'tensorflow', 'pca', 'random forest', 'shiny', 'cloud', 'reinforcement', 'react', 'recurrent', 'exploratory', 'graph', 'biostatistics', 'salesforce', 'anomaly', 'scala', 'xgboost', 'unsupervised', 'snowflake', 'angular', 'azure', 'scikit', 'cleaning', 'keras', 'segmentation', 'probability', 'theano', 'matplotlib', 'forecasting', 'sql', 'classification', 'perl', 'supervised', 'recommendations', 'neural network', 'scipy', 'cleansing', 'dt', 'research', 'dashboard', 'flask', 'linux', 'blockchain', 'text analytics', 'ocr', 'birt', 'causality', 'geospatial', 'sequencing', 'net', 'etl', 'decision tree', 'data mining', 'qlik', 'hive', 'optimization', 'regression', 'gis', 'logistic', 'computer vision', 'd3', 'recommender', 'lambda', 'prediction', 'jupyter', 'machine learning', 'pytorch', 'spacy', 'sklearn', 'optimizing', 'php', 'django', 'git', 'rstan', 'kubernetes', 's3', 'chatbot', 'convolutional', 'tensor', 'experimental design', 'tf', 'dimensionality reduction', 'correlation', 'support vector machine', 'tableau', 'machine vision', 'deep learning', 'javascript', 'aws', 'hbase', 'elasticsearch', 'clustering', 'bioinformatics', 'pandas', 'java', 'time series']\n"
     ]
    }
   ],
   "source": [
    "CS_word_counts = {word: merged_df['Description'].str.count(re.escape(word)).sum() for word in CS_keywords}\n",
    "CS_keyword_freq = pd.DataFrame(list(CS_word_counts.items()), columns=['CS_keyword', 'CS_keyword_Count'])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "CS_keyword_freq = CS_keyword_freq[CS_keyword_freq['CS_keyword_Count'] !=0]\n",
    "\n",
    "print(CS_keyword_freq['CS_keyword'].tolist())\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb143b9f",
   "metadata": {},
   "source": [
    "## Adding the keywords columns in the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4289c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
      "/var/folders/0l/srjf8wrn45d3c527z89b0d9m0000gn/T/ipykernel_2409/263324470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>skill_keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>javascript</th>\n",
       "      <th>aws</th>\n",
       "      <th>hbase</th>\n",
       "      <th>elasticsearch</th>\n",
       "      <th>clustering</th>\n",
       "      <th>bioinformatics</th>\n",
       "      <th>pandas</th>\n",
       "      <th>java</th>\n",
       "      <th>time series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Cross Asset Desk Strategist T...</td>\n",
       "      <td>Data Scientist - Cross Asset Desk Strategist T...</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>90000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist - Infectious Disease and...</td>\n",
       "      <td>Senior Data Scientist - Infectious Disease and...</td>\n",
       "      <td>Carolinas HealthCare System</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>125000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist, Advanced Marketing Anal...</td>\n",
       "      <td>Senior Data Scientist, Advanced Marketing Anal...</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>125000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TV Data Scientist in Burlington, MA</td>\n",
       "      <td>TV Data Scientist in Burlington, MA Our servic...</td>\n",
       "      <td>LiveRamp</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>MA</td>\n",
       "      <td>125000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV Data Scientist in Burlington, MA</td>\n",
       "      <td>TV Data Scientist in Burlington, MA ABOUT THIS...</td>\n",
       "      <td>LiveRamp</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>MA</td>\n",
       "      <td>125000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2024 R&amp;D Summer Intern- Track 2</td>\n",
       "      <td>About Alcon: As the global leader in eye care,...</td>\n",
       "      <td>Alcon</td>\n",
       "      <td>Geneva</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>93600</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2024 R&amp;D Summer Intern- Track 2</td>\n",
       "      <td>About Alcon: As the global leader in eye care,...</td>\n",
       "      <td>Alcon</td>\n",
       "      <td>Geneva</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>93600</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Piper Companies is looking for a Sr. Full Stac...</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>McLean</td>\n",
       "      <td>VA</td>\n",
       "      <td>156000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>Metal Additive Manufacturing - Postdoctoral Re...</td>\n",
       "      <td>Company Description Join us and make YOUR mark...</td>\n",
       "      <td>Lawrence Livermore National Laboratory</td>\n",
       "      <td>Livermore</td>\n",
       "      <td>CA</td>\n",
       "      <td>108840</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>Epidemiology Investigator 2 (Hybrid Eligible)</td>\n",
       "      <td>About Us Our mission is to save lives, reduce ...</td>\n",
       "      <td>Ohio Department of Public Safety</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>57907</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Data Scientist - Cross Asset Desk Strategist T...   \n",
       "1     Senior Data Scientist - Infectious Disease and...   \n",
       "2     Senior Data Scientist, Advanced Marketing Anal...   \n",
       "3                   TV Data Scientist in Burlington, MA   \n",
       "4                   TV Data Scientist in Burlington, MA   \n",
       "...                                                 ...   \n",
       "1434                    2024 R&D Summer Intern- Track 2   \n",
       "1435                    2024 R&D Summer Intern- Track 2   \n",
       "1436                               Full Stack Developer   \n",
       "1437  Metal Additive Manufacturing - Postdoctoral Re...   \n",
       "1438      Epidemiology Investigator 2 (Hybrid Eligible)   \n",
       "\n",
       "                                            Description  \\\n",
       "0     Data Scientist - Cross Asset Desk Strategist T...   \n",
       "1     Senior Data Scientist - Infectious Disease and...   \n",
       "2     Senior Data Scientist, Advanced Marketing Anal...   \n",
       "3     TV Data Scientist in Burlington, MA Our servic...   \n",
       "4     TV Data Scientist in Burlington, MA ABOUT THIS...   \n",
       "...                                                 ...   \n",
       "1434  About Alcon: As the global leader in eye care,...   \n",
       "1435  About Alcon: As the global leader in eye care,...   \n",
       "1436  Piper Companies is looking for a Sr. Full Stac...   \n",
       "1437  Company Description Join us and make YOUR mark...   \n",
       "1438  About Us Our mission is to save lives, reduce ...   \n",
       "\n",
       "                                Company Name        City        State  Salary  \\\n",
       "0                             Morgan Stanley    New York           NY   90000   \n",
       "1                Carolinas HealthCare System   Charlotte           NC  125000   \n",
       "2                                    Spotify    New York           NY  125000   \n",
       "3                                   LiveRamp  Burlington           MA  125000   \n",
       "4                                   LiveRamp  Burlington           MA  125000   \n",
       "...                                      ...         ...          ...     ...   \n",
       "1434                                   Alcon      Geneva  Switzerland   93600   \n",
       "1435                                   Alcon      Geneva  Switzerland   93600   \n",
       "1436                         Piper Companies      McLean           VA  156000   \n",
       "1437  Lawrence Livermore National Laboratory   Livermore           CA  108840   \n",
       "1438        Ohio Department of Public Safety    Columbus         Ohio   57907   \n",
       "\n",
       "        Year  Month   Day  skill_keywords  ...  deep learning  javascript  \\\n",
       "0     2019.0    8.0  20.0               1  ...              0           0   \n",
       "1     2019.0    9.0   6.0               3  ...              0           0   \n",
       "2     2019.0    8.0  23.0               6  ...              0           0   \n",
       "3     2019.0    8.0   2.0               5  ...              0           0   \n",
       "4     2019.0    8.0   2.0               5  ...              0           0   \n",
       "...      ...    ...   ...             ...  ...            ...         ...   \n",
       "1434  2019.0    9.0  16.0               6  ...              3           0   \n",
       "1435  2019.0    9.0  16.0               6  ...              3           0   \n",
       "1436  2019.0    9.0  16.0               1  ...              0           2   \n",
       "1437  2019.0    9.0  16.0               3  ...              0           0   \n",
       "1438  2019.0    9.0  16.0               2  ...              0           0   \n",
       "\n",
       "      aws  hbase  elasticsearch  clustering  bioinformatics  pandas  java  \\\n",
       "0       0      0              0           0               0       0     0   \n",
       "1       0      0              0           0               0       0     0   \n",
       "2       0      0              0           0               0       0     0   \n",
       "3       0      0              0           1               0       0     0   \n",
       "4       0      0              0           1               0       0     0   \n",
       "...   ...    ...            ...         ...             ...     ...   ...   \n",
       "1434    0      0              0           0               0       0     0   \n",
       "1435    0      0              0           0               0       0     0   \n",
       "1436    0      0              0           0               0       0     8   \n",
       "1437    1      0              0           0               0       0     0   \n",
       "1438    3      0              0           0               0       0     0   \n",
       "\n",
       "      time series  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "1434            0  \n",
       "1435            0  \n",
       "1436            0  \n",
       "1437            0  \n",
       "1438            0  \n",
       "\n",
       "[1439 rows x 135 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for keyword in CS_keyword_freq['CS_keyword'].tolist():\n",
    "    merged_df[keyword] = merged_df['Description'].apply(lambda x: x.lower().count(keyword.lower()))\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f867ce41",
   "metadata": {},
   "source": [
    "## Chekcing correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e9e41861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary                         1.000000\n",
      "python                         0.204396\n",
      "tool_keywords                  0.180845\n",
      "skill_keywords                 0.142638\n",
      "rstan                          0.137304\n",
      "sql                            0.114070\n",
      "intern                         0.098171\n",
      "optimization                   0.087313\n",
      "spark                          0.084799\n",
      "tableau                        0.082866\n",
      "dashboard                      0.077772\n",
      "classification                 0.077461\n",
      "recommendations                0.077049\n",
      "dash                           0.076997\n",
      "visualization                  0.074599\n",
      "scala                          0.072129\n",
      "exploratory                    0.071435\n",
      "deep learning                  0.071239\n",
      "birt                           0.070149\n",
      "machine learning               0.069004\n",
      "clustering                     0.067453\n",
      "redshift                       0.065721\n",
      "regression                     0.065007\n",
      "net                            0.064953\n",
      "neural network                 0.063882\n",
      "git                            0.063392\n",
      "jupyter                        0.063098\n",
      "gis                            0.062398\n",
      "cleaning                       0.061869\n",
      "a/b testing                    0.061130\n",
      "hypothesis                     0.060873\n",
      "tf                             0.060762\n",
      "data mining                    0.060265\n",
      "docker                         0.057989\n",
      "senior                         0.057344\n",
      "hive                           0.057278\n",
      "unsupervised                   0.056247\n",
      "aws                            0.055675\n",
      "sas                            0.055284\n",
      "random forest                  0.055085\n",
      "supervised                     0.054958\n",
      "kubernetes                     0.054842\n",
      "research                       0.054062\n",
      "tensor                         0.052552\n",
      "decision tree                  0.052298\n",
      "pca                            0.050866\n",
      "dimensionality reduction       0.050729\n",
      "scikit                         0.050302\n",
      "s3                             0.049847\n",
      "tensorflow                     0.049356\n",
      "logistic                       0.048282\n",
      "perl                           0.048216\n",
      "pandas                         0.047269\n",
      "php                            0.046379\n",
      "cloud                          0.045657\n",
      "pyspark                        0.045092\n",
      "correlation                    0.043777\n",
      "natural language processing    0.043554\n",
      "anomaly                        0.042260\n",
      "pytorch                        0.041394\n",
      "etl                            0.039337\n",
      "sklearn                        0.039163\n",
      "shiny                          0.037937\n",
      "java                           0.037274\n",
      "h2o                            0.036854\n",
      "node                           0.036721\n",
      "numpy                          0.035751\n",
      "scipy                          0.035514\n",
      "salesforce                     0.034439\n",
      "qlik                           0.034431\n",
      "keras                          0.034245\n",
      "dt                             0.034029\n",
      "javascript                     0.032615\n",
      "biostatistics                  0.032490\n",
      "rvest                          0.031772\n",
      "bokeh                          0.030899\n",
      "ggplot2                        0.030302\n",
      "machine vision                 0.028567\n",
      "snowflake                      0.028293\n",
      "geospatial                     0.028214\n",
      "experimental design            0.027675\n",
      "lambda                         0.027565\n",
      "hyperparameter                 0.027330\n",
      "forecasting                    0.026360\n",
      "github                         0.026207\n",
      "linux                          0.026135\n",
      "cleansing                      0.025950\n",
      "bioinformatics                 0.025272\n",
      "matplotlib                     0.024973\n",
      "blockchain                     0.023645\n",
      "azure                          0.023459\n",
      "Month                          0.023263\n",
      "recurrent                      0.022573\n",
      "rust                           0.022105\n",
      "recommender                    0.020917\n",
      "Day                            0.020814\n",
      "nearest neighbors              0.019319\n",
      "computer vision                0.018932\n",
      "causality                      0.015849\n",
      "chatbot                        0.015413\n",
      "support vector machine         0.014566\n",
      "plotly                         0.013850\n",
      "xgboost                        0.012381\n",
      "text analytics                 0.012149\n",
      "flask                          0.012093\n",
      "django                         0.011599\n",
      "reinforcement                  0.010550\n",
      "seaborn                        0.009920\n",
      "graph                          0.008499\n",
      "elasticsearch                  0.008449\n",
      "boosting                       0.008211\n",
      "segmentation                   0.007776\n",
      "theano                         0.007590\n",
      "time series                    0.007288\n",
      "hbase                          0.007245\n",
      "prediction                     0.006475\n",
      "probability                    0.005984\n",
      "react                          0.005854\n",
      "tuning                         0.005377\n",
      "convolutional                  0.005283\n",
      "d3                             0.005279\n",
      "spacy                          0.005009\n",
      "nltk                           0.003584\n",
      "ocr                            0.003497\n",
      "angular                        0.002418\n",
      "sequencing                     0.002062\n",
      "bandit                         0.000943\n",
      "optimizing                     0.000555\n",
      "normalization                  0.000440\n",
      "Year                                NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "merged_df_corr = merged_df.drop(['Description', 'Title', 'Company Name', 'City', 'State'], axis=1)\n",
    "\n",
    "salary_column = merged_df_corr['Salary']\n",
    "correlations = merged_df_corr.corrwith(salary_column)\n",
    "\n",
    "\n",
    "sorted_correlations = correlations.abs().sort_values(ascending=False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(sorted_correlations)\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b2576",
   "metadata": {},
   "source": [
    "## Select the top 20 correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ebe95862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Salary</th>\n",
       "      <th>python</th>\n",
       "      <th>tool_keywords</th>\n",
       "      <th>skill_keywords</th>\n",
       "      <th>rstan</th>\n",
       "      <th>...</th>\n",
       "      <th>tableau</th>\n",
       "      <th>dashboard</th>\n",
       "      <th>classification</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>dash</th>\n",
       "      <th>visualization</th>\n",
       "      <th>scala</th>\n",
       "      <th>exploratory</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>birt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Cross Asset Desk Strategist T...</td>\n",
       "      <td>Data Scientist - Cross Asset Desk Strategist T...</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>90000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist - Infectious Disease and...</td>\n",
       "      <td>Senior Data Scientist - Infectious Disease and...</td>\n",
       "      <td>Carolinas HealthCare System</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>125000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist, Advanced Marketing Anal...</td>\n",
       "      <td>Senior Data Scientist, Advanced Marketing Anal...</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>125000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TV Data Scientist in Burlington, MA Our servic...</td>\n",
       "      <td>TV Data Scientist in Burlington, MA</td>\n",
       "      <td>LiveRamp</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>MA</td>\n",
       "      <td>125000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV Data Scientist in Burlington, MA ABOUT THIS...</td>\n",
       "      <td>TV Data Scientist in Burlington, MA</td>\n",
       "      <td>LiveRamp</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>MA</td>\n",
       "      <td>125000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>About Alcon: As the global leader in eye care,...</td>\n",
       "      <td>2024 R&amp;D Summer Intern- Track 2</td>\n",
       "      <td>Alcon</td>\n",
       "      <td>Geneva</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>93600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>About Alcon: As the global leader in eye care,...</td>\n",
       "      <td>2024 R&amp;D Summer Intern- Track 2</td>\n",
       "      <td>Alcon</td>\n",
       "      <td>Geneva</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>93600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>Piper Companies is looking for a Sr. Full Stac...</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>McLean</td>\n",
       "      <td>VA</td>\n",
       "      <td>156000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>Company Description Join us and make YOUR mark...</td>\n",
       "      <td>Metal Additive Manufacturing - Postdoctoral Re...</td>\n",
       "      <td>Lawrence Livermore National Laboratory</td>\n",
       "      <td>Livermore</td>\n",
       "      <td>CA</td>\n",
       "      <td>108840</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>About Us Our mission is to save lives, reduce ...</td>\n",
       "      <td>Epidemiology Investigator 2 (Hybrid Eligible)</td>\n",
       "      <td>Ohio Department of Public Safety</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>57907</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Description  \\\n",
       "0     Data Scientist - Cross Asset Desk Strategist T...   \n",
       "1     Senior Data Scientist - Infectious Disease and...   \n",
       "2     Senior Data Scientist, Advanced Marketing Anal...   \n",
       "3     TV Data Scientist in Burlington, MA Our servic...   \n",
       "4     TV Data Scientist in Burlington, MA ABOUT THIS...   \n",
       "...                                                 ...   \n",
       "1434  About Alcon: As the global leader in eye care,...   \n",
       "1435  About Alcon: As the global leader in eye care,...   \n",
       "1436  Piper Companies is looking for a Sr. Full Stac...   \n",
       "1437  Company Description Join us and make YOUR mark...   \n",
       "1438  About Us Our mission is to save lives, reduce ...   \n",
       "\n",
       "                                                  Title  \\\n",
       "0     Data Scientist - Cross Asset Desk Strategist T...   \n",
       "1     Senior Data Scientist - Infectious Disease and...   \n",
       "2     Senior Data Scientist, Advanced Marketing Anal...   \n",
       "3                   TV Data Scientist in Burlington, MA   \n",
       "4                   TV Data Scientist in Burlington, MA   \n",
       "...                                                 ...   \n",
       "1434                    2024 R&D Summer Intern- Track 2   \n",
       "1435                    2024 R&D Summer Intern- Track 2   \n",
       "1436                               Full Stack Developer   \n",
       "1437  Metal Additive Manufacturing - Postdoctoral Re...   \n",
       "1438      Epidemiology Investigator 2 (Hybrid Eligible)   \n",
       "\n",
       "                                Company Name        City        State  Salary  \\\n",
       "0                             Morgan Stanley    New York           NY   90000   \n",
       "1                Carolinas HealthCare System   Charlotte           NC  125000   \n",
       "2                                    Spotify    New York           NY  125000   \n",
       "3                                   LiveRamp  Burlington           MA  125000   \n",
       "4                                   LiveRamp  Burlington           MA  125000   \n",
       "...                                      ...         ...          ...     ...   \n",
       "1434                                   Alcon      Geneva  Switzerland   93600   \n",
       "1435                                   Alcon      Geneva  Switzerland   93600   \n",
       "1436                         Piper Companies      McLean           VA  156000   \n",
       "1437  Lawrence Livermore National Laboratory   Livermore           CA  108840   \n",
       "1438        Ohio Department of Public Safety    Columbus         Ohio   57907   \n",
       "\n",
       "      python  tool_keywords  skill_keywords  rstan  ...  tableau  dashboard  \\\n",
       "0          1              1               1      0  ...        0          0   \n",
       "1          0              2               3      1  ...        0          0   \n",
       "2          1              5               6      1  ...        1          0   \n",
       "3          1              8               5      2  ...        1          1   \n",
       "4          1              8               5      2  ...        1          1   \n",
       "...      ...            ...             ...    ...  ...      ...        ...   \n",
       "1434       0              1               6      5  ...        0          0   \n",
       "1435       0              1               6      5  ...        0          0   \n",
       "1436       0              4               1      1  ...        0          0   \n",
       "1437       1              2               3      2  ...        0          0   \n",
       "1438       0              3               2      0  ...        2          2   \n",
       "\n",
       "      classification  recommendations  dash  visualization  scala  \\\n",
       "0                  0                0     0              1      0   \n",
       "1                  0                0     0              1      1   \n",
       "2                  0                1     0              1      0   \n",
       "3                  0                0     1              1      0   \n",
       "4                  0                0     1              1      0   \n",
       "...              ...              ...   ...            ...    ...   \n",
       "1434               0                0     0              1      0   \n",
       "1435               0                0     0              1      0   \n",
       "1436               0                0     0              0      1   \n",
       "1437               0                0     0              0      0   \n",
       "1438               0                2     2              0      0   \n",
       "\n",
       "      exploratory  deep learning  birt  \n",
       "0               0              0     0  \n",
       "1               0              0     0  \n",
       "2               0              0     0  \n",
       "3               0              0     0  \n",
       "4               0              0     0  \n",
       "...           ...            ...   ...  \n",
       "1434            0              3     0  \n",
       "1435            0              3     0  \n",
       "1436            0              0     0  \n",
       "1437            0              0     0  \n",
       "1438            0              0     1  \n",
       "\n",
       "[1439 rows x 24 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = merged_df[['Description', 'Title', 'Company Name', 'City', 'State','Salary'\n",
    "                      ,'python','tool_keywords','skill_keywords','rstan' ,'sql','intern', 'optimization','spark'\n",
    "                      ,'tableau','dashboard','classification','recommendations','dash','visualization'\n",
    "                      ,'scala','exploratory','deep learning','birt']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8de66a",
   "metadata": {},
   "source": [
    "## Push the dataset to Amazon S3 datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cb242bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '2ZF9B428VDHX6JVZ',\n",
       "  'HostId': 'Gsl0Mdo5yhx15efWL4RjquYXf/1TiyokLk8uyFh53A12O/n+emIunkbAjUwO3AMjCG2ivUw36JU=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Gsl0Mdo5yhx15efWL4RjquYXf/1TiyokLk8uyFh53A12O/n+emIunkbAjUwO3AMjCG2ivUw36JU=',\n",
       "   'x-amz-request-id': '2ZF9B428VDHX6JVZ',\n",
       "   'date': 'Tue, 20 Feb 2024 22:03:23 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"e4397dc8797d66f8e4d7f108ed0f8944\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 1},\n",
       " 'ETag': '\"e4397dc8797d66f8e4d7f108ed0f8944\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file_key = 'with_20_keywords.csv'\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "final_df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "s3.put_object(Body = csv_buffer.getvalue(), Bucket = bucket_name, Key=output_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef0886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
