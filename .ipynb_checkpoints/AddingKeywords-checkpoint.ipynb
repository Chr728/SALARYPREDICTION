{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737dfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1014efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re \n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import io\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import pearsonr\n",
    "import textdistance\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87444577",
   "metadata": {},
   "source": [
    "## Credentials for Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4694f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = 'AKIAZQ3DOOYC7J5PI25Z'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "bucket_name = 'comp333bucket'\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208713f0",
   "metadata": {},
   "source": [
    "## The list contains generic CS keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b702dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CS_keywords = set(['python', 'pytorch', 'sql', 'mxnet', 'mlflow', 'einstein', 'theano', 'pyspark', 'solr', 'mahout',\n",
    " 'cassandra', 'aws', 'powerpoint', 'spark', 'pig', 'sas', 'java', 'nosql', 'docker', 'salesforce', 'scala', 'c++', 'net', 'tableau', 'pandas', 'scikitlearn', 'sklearn', 'matlab', 'scala', 'keras', 'tensorflow', 'clojure',\n",
    " 'caffe', 'scipy', 'numpy', 'matplotlib', 'vba', 'spss', 'linux', 'azure', 'cloud', 'gcp', 'mongodb', 'mysql', 'oracle',\n",
    " 'redshift', 'snowflake', 'kafka', 'javascript', 'qlik', 'jupyter', 'perl', 'bigquery', 'unix', 'react',\n",
    " 'scikit', 'powerbi', 's3', 'ec2', 'lambda', 'ssrs', 'kubernetes', 'hana', 'spacy', 'tf', 'django', 'sagemaker',\n",
    " 'seaborn', 'mllib', 'github', 'git', 'elasticsearch', 'splunk', 'airflow', 'looker', 'rapidminer', 'birt', 'pentaho',\n",
    "'jquery', 'nodejs', 'd3', 'plotly', 'bokeh', 'xgboost', 'rstudio', 'shiny', 'dash', 'h20', 'h2o', 'hadoop', 'mapreduce',\n",
    " 'hive', 'cognos', 'angular', 'nltk', 'flask', 'node', 'firebase', 'bigtable', 'rust', 'php', 'cntk', 'lightgbm',\n",
    " 'kubeflow', 'rpython', 'unixlinux', 'postgressql', 'postgresql', 'postgres', 'hbase', 'dask', 'ruby', 'julia', 'tensor',\n",
    " 'dplyr','ggplot2','esquisse','bioconductor','shiny','lubridate','knitr','mlr','quanteda','dt','rcrawler','caret','rmarkdown',\n",
    " 'leaflet','janitor','ggvis','plotly','rcharts','rbokeh','broom','stringr','magrittr','slidify','rvest',\n",
    " 'rmysql','rsqlite','prophet','glmnet','text2vec','snowballc','quantmod','rstan','swirl','datasciencer', \n",
    " 'amazon web services', 'google cloud', 'sql server',\n",
    "  'cleansing', 'chatbot', 'cleaning', 'blockchain', 'causality', 'correlation', 'bandit', 'anomaly', 'kpi',\n",
    " 'dashboard', 'geospatial', 'ocr',  'pca', 'gis', 'svm', 'svd', 'tuning', 'hyperparameter', 'hypothesis',\n",
    " 'salesforcecom', 'segmentation', 'biostatistics', 'unsupervised', 'supervised', 'exploratory',\n",
    " 'recommender', 'recommendations', 'research', 'sequencing', 'probability', 'reinforcement', 'graph', 'bioinformatics',\n",
    "  'knn', 'etl', 'normalization', 'classification', 'optimizing', 'prediction', 'forecasting',\n",
    " 'clustering', 'optimization', 'visualization', 'nlp', 'c#',\n",
    " 'regression', 'logistic', 'cnn', 'glm',\n",
    " 'rnn', 'lstm', 'gbm', 'boosting', 'recurrent', 'convolutional', 'bayesian',\n",
    " 'bayes', 'random forest', 'natural language processing', 'machine learning', 'decision tree', 'deep learning', 'experimental design',\n",
    " 'time series', 'nearest neighbors', 'neural network', 'support vector machine', 'computer vision', 'machine vision', 'dimensionality reduction',\n",
    " 'text analytics',  'a/b testing', 'data mining', 'kajsadouas', 'senior','intern', 'Data', ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e0bb4",
   "metadata": {},
   "source": [
    "## Get the list of unique keywords that appear in the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a5067d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>CS_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Cross Asset Desk Strategist T...</td>\n",
       "      <td>Data Scientist - Cross Asset Desk Strategist T...</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>90000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist - Infectious Disease and...</td>\n",
       "      <td>Senior Data Scientist - Infectious Disease and...</td>\n",
       "      <td>Carolinas HealthCare System</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>125000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist, Advanced Marketing Anal...</td>\n",
       "      <td>Senior Data Scientist, Advanced Marketing Anal...</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>125000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Data Scientist - Cross Asset Desk Strategist T...   \n",
       "1  Senior Data Scientist - Infectious Disease and...   \n",
       "2  Senior Data Scientist, Advanced Marketing Anal...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Data Scientist - Cross Asset Desk Strategist T...   \n",
       "1  Senior Data Scientist - Infectious Disease and...   \n",
       "2  Senior Data Scientist, Advanced Marketing Anal...   \n",
       "\n",
       "                  Company Name       City State  Salary    Year  Month   Day  \\\n",
       "0               Morgan Stanley   New York    NY   90000  2019.0    8.0  20.0   \n",
       "1  Carolinas HealthCare System  Charlotte    NC  125000  2019.0    9.0   6.0   \n",
       "2                      Spotify   New York    NY  125000  2019.0    8.0  23.0   \n",
       "\n",
       "   CS_keywords  \n",
       "0            2  \n",
       "1            5  \n",
       "2           11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_key = 'merged_dataset.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "content = obj['Body'].read()\n",
    "merged_df = pd.read_csv(BytesIO(content), engine='python')\n",
    "display(merged_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c584245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with highest correlation with salary: [('data', 0.19391532632517758), ('work', 0.19321194905212666), ('python', 0.19274615100484604), ('experience', 0.17160888922427728), ('scientist', 0.1694373767984956), ('new', 0.1515917445517305), ('opportunities', 0.1515849651560083), ('insights', 0.14636544334120355), ('skills', 0.14592456844144214), ('problems', 0.13800163541233004), ('help', 0.136008261411012), ('communication', 0.13149529867697363), ('drive', 0.12995225717366998), ('including', 0.1293120716491419), ('build', 0.12915903958543679), ('team', 0.12772669588177799), ('programming', 0.12728079917560337), ('passion', 0.12617108310408576), ('statistics', 0.12421543675665123), ('ca', 0.12335608908969603), ('learn', 0.12236956579110002), ('business', 0.12191636270814088), ('responsibilities', 0.12092818595962083), ('sql', 0.1198910917845229), ('key', 0.11849593653677092), ('actionable', 0.11677121335804957), ('ability', 0.11661494905309416), ('analyses', 0.11562357913714841), ('environment', 0.1145813981092616), ('open', 0.1130367884906634), ('knowledge', 0.11148885489889437), ('understand', 0.11106940841405025), ('tools', 0.10870872175675443), ('reports', 0.10861480831796641), ('stakeholders', 0.10684046254349956), ('computer', 0.10574665888566526), ('metrics', 0.10446247860869366), ('improvement', 0.10375161055905811), ('develop', 0.10367696768321698), ('make', 0.10212472184525259), ('preferred', 0.09966470607600884), ('qualifications', 0.0986827553953612), ('end', 0.0985959543422339), ('initiatives', 0.09804661714249929), ('organize', 0.09715425993745838), ('related', 0.09619505447077736), ('life', 0.09530377097356402), ('future', 0.09218090384522347), ('believe', 0.0917462679539768), ('values', 0.09148299176459126), ('quickly', 0.09140349348408325), ('verbal', 0.09034326525072023), ('growth', 0.09007226110279311), ('well', 0.08982210810915332), ('time', 0.08888348810069482), ('closely', 0.08538475944854224), ('tableau', 0.08474564829325867), ('required', 0.08391851591263982), ('excel', 0.08304316113525961), ('phd', 0.08170609662401518), ('inform', 0.07945116000521693), ('big', 0.07933372887734366), ('effectively', 0.07918515166856002), ('advance', 0.07871282725959355), ('throughout', 0.07838738298860079), ('hadoop', 0.07778158749910721), ('20', 0.07739348076537012), ('system', 0.07570066996865502), ('transform', 0.07395074546244002), ('together', 0.07200742474184), ('overview', 0.07161096986629839), ('similar', 0.07133575523771754), ('dashboards', 0.07071552976869969), ('want', 0.06888865392364851), ('physics', 0.0662127713326198), ('language', 0.06564071571163049), ('enjoy', 0.06542254805485123), ('highly', 0.06531574912694495), ('50', 0.06435619808389523), ('track', 0.06062862937318238), ('public', 0.05899686490659328), ('accuracy', 0.051313200218434475), ('minimum', 0.05089800943070276), ('kafka', 0.04939711993839886), ('check', 0.048022240062381406), ('10', 0.0471495807853745), ('40', 0.03940425477143885), ('maximize', 0.03693889880581533), ('numpy', 0.033645481114484184), ('today', 0.03342892704883181)]\n"
     ]
    }
   ],
   "source": [
    "# Suppress PerformanceWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented.*\")\n",
    "\n",
    "# Tokenize the words and remove stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "merged_df['Description'] = merged_df['Description'].apply(lambda x: ' '.join([word.capitalize() for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "\n",
    "# Count word frequencies\n",
    "word_frequencies = {}\n",
    "for description in merged_df['Description']:\n",
    "    words = word_tokenize(description)\n",
    "    for word in words:\n",
    "        word = word.lower()  # Convert to lowercase for consistency\n",
    "        if word not in word_frequencies:\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1\n",
    "\n",
    "# Filter out words with frequency above 50\n",
    "frequent_words = {word: freq for word, freq in word_frequencies.items() if freq > 50}\n",
    "\n",
    "# Create bag-of-words representation\n",
    "vectorizer = CountVectorizer(vocabulary=frequent_words.keys())\n",
    "X = vectorizer.fit_transform(merged_df['Description'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlations = {}\n",
    "for word in frequent_words:\n",
    "    idx = vectorizer.vocabulary_.get(word)\n",
    "    if idx is not None:\n",
    "        word_vector = X[:, idx].toarray().flatten()\n",
    "        correlation, _ = pearsonr(word_vector, merged_df['Salary'])\n",
    "        if not pd.isnull(correlation):  # Exclude words with NaN correlation\n",
    "            correlations[word] = abs(correlation)\n",
    "\n",
    "# Find redundant words based on Jaro-Winkler similarity and keep only the one with the highest correlation\n",
    "threshold = 0.7 # You can adjust this threshold as needed\n",
    "redundant_words = set()\n",
    "for word1 in correlations:\n",
    "    for word2 in correlations:\n",
    "        if word1 != word2 and textdistance.jaro_winkler.similarity(word1, word2) > threshold:\n",
    "            if correlations[word1] > correlations[word2]:\n",
    "                redundant_words.add(word2)\n",
    "            else:\n",
    "                redundant_words.add(word1)\n",
    "\n",
    "# Remove redundant words from frequent_words\n",
    "frequent_words = {word: freq for word, freq in frequent_words.items() if word not in redundant_words}\n",
    "\n",
    "# Sort the words based on their correlation with the salary column and remove redundant words\n",
    "sorted_correlations = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_correlations = [(word, corr) for word, corr in sorted_correlations if word not in redundant_words]\n",
    "\n",
    "#print(\"Words with frequency above 50 and not redundant:\", len(frequent_words))\n",
    "print(\"Words with highest correlation with salary:\", sorted_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1af1e",
   "metadata": {},
   "source": [
    "## Adding top 30 correlated keyword columns in the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd49015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add frequency columns for top 30 correlated keywords\n",
    "for word, _ in sorted_correlations[:200]:\n",
    "    merged_df[word] = merged_df['Description'].apply(lambda x: sum(textdistance.jaro_winkler.similarity(word, w) > threshold for w in word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b77956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Description', 'Company Name', 'City', 'State', 'Salary',\n",
      "       'Year', 'Month', 'Day', 'CS_keywords', 'data', 'work', 'python',\n",
      "       'experience', 'scientist', 'new', 'opportunities', 'insights', 'skills',\n",
      "       'problems', 'help', 'communication', 'drive', 'including', 'build',\n",
      "       'team', 'programming', 'passion', 'statistics', 'ca', 'learn',\n",
      "       'business', 'responsibilities', 'sql', 'key', 'actionable', 'ability',\n",
      "       'analyses', 'environment', 'open'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f867ce41",
   "metadata": {},
   "source": [
    "## Validating correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9e41861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary              1.000000\n",
      "work                0.220396\n",
      "data                0.195275\n",
      "python              0.187750\n",
      "experience          0.187522\n",
      "including           0.186487\n",
      "CS_keywords         0.182668\n",
      "communication       0.177197\n",
      "actionable          0.176959\n",
      "problems            0.172678\n",
      "open                0.171065\n",
      "drive               0.169938\n",
      "analyses            0.169619\n",
      "new                 0.167711\n",
      "team                0.166803\n",
      "insights            0.165704\n",
      "learn               0.163716\n",
      "scientist           0.162828\n",
      "passion             0.159724\n",
      "help                0.157120\n",
      "skills              0.148692\n",
      "ability             0.142484\n",
      "build               0.140606\n",
      "ca                  0.136062\n",
      "business            0.135740\n",
      "statistics          0.135301\n",
      "opportunities       0.128712\n",
      "responsibilities    0.127616\n",
      "sql                 0.126441\n",
      "key                 0.122934\n",
      "programming         0.113352\n",
      "environment         0.112988\n",
      "Month               0.022445\n",
      "Day                 0.020837\n",
      "Year                     NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "merged_df_corr = merged_df.drop(['Description', 'Title', 'Company Name', 'City', 'State'], axis=1)\n",
    "\n",
    "salary_column = merged_df_corr['Salary']\n",
    "correlations = merged_df_corr.corrwith(salary_column)\n",
    "\n",
    "\n",
    "sorted_correlations = correlations.abs().sort_values(ascending=False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(sorted_correlations)\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "062eeedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>CS_keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>learn</th>\n",
       "      <th>business</th>\n",
       "      <th>responsibilities</th>\n",
       "      <th>sql</th>\n",
       "      <th>key</th>\n",
       "      <th>actionable</th>\n",
       "      <th>ability</th>\n",
       "      <th>analyses</th>\n",
       "      <th>environment</th>\n",
       "      <th>open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Cross Asset Desk Strategist T...</td>\n",
       "      <td>Data Scientist - Cross Asset Desk Strategist T...</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>90000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist - Infectious Disease and...</td>\n",
       "      <td>Senior Data Scientist - Infectious Disease Inf...</td>\n",
       "      <td>Carolinas HealthCare System</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>125000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Data Scientist - Cross Asset Desk Strategist T...   \n",
       "1  Senior Data Scientist - Infectious Disease and...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Data Scientist - Cross Asset Desk Strategist T...   \n",
       "1  Senior Data Scientist - Infectious Disease Inf...   \n",
       "\n",
       "                  Company Name       City State  Salary    Year  Month   Day  \\\n",
       "0               Morgan Stanley   New York    NY   90000  2019.0    8.0  20.0   \n",
       "1  Carolinas HealthCare System  Charlotte    NC  125000  2019.0    9.0   6.0   \n",
       "\n",
       "   CS_keywords  ...  learn  business  responsibilities  sql  key  actionable  \\\n",
       "0            2  ...      5         2                 1    0    0           0   \n",
       "1            5  ...      5         5                 0    0    1           8   \n",
       "\n",
       "   ability  analyses  environment  open  \n",
       "0        2         8            1     0  \n",
       "1        7         7            5     4  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8de66a",
   "metadata": {},
   "source": [
    "## Push the dataset to Amazon S3 datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb242bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'NTQWN6F44HYV27D6',\n",
       "  'HostId': 'H81NWr4E2F/x257Om3+dR8nnvfq7yxge4PEG74edSAcTsVcDTqo9JeVnE3XCybpZtL3+pqsSLAk=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'H81NWr4E2F/x257Om3+dR8nnvfq7yxge4PEG74edSAcTsVcDTqo9JeVnE3XCybpZtL3+pqsSLAk=',\n",
       "   'x-amz-request-id': 'NTQWN6F44HYV27D6',\n",
       "   'date': 'Thu, 21 Mar 2024 00:31:32 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"a42b777a427043e204ef6951c215e915\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"a42b777a427043e204ef6951c215e915\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file_key = 'with_20_keywords.csv'\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "merged_df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "s3.put_object(Body = csv_buffer.getvalue(), Bucket = bucket_name, Key=output_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae50616",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e9378",
   "metadata": {},
   "source": [
    "#### Before normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e228332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df['Salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "final_df.loc[:, 'Salary'] = scaler.fit_transform(final_df['Salary'].values.reshape(-1, 1))\n",
    "# If we want to reverse the normalization\n",
    "# final_df.loc[:, 'Salary'] = scaler.inverse_transform(final_df['Salary'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010944f",
   "metadata": {},
   "source": [
    "#### After normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a54da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df['Salary'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
